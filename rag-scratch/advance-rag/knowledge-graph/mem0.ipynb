{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF Knowledge Graph\n",
    "\n",
    "![rag flow image](graph-db.png \"RAG FLOW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat application with Mem0 (vector + graph)\n",
    "\n",
    "![rag flow image](chat-application.png \"RAG FLOW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from mem0 import Memory\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ.get('OPEN_API_KEY')\n",
    "MEM0_API_KEY = os.environ.get('MEM0_API_KEY')\n",
    "NEO4J_URL = \"bolt://localhost:7687\"\n",
    "NEO4J_URI = os.environ.get('NEO4J_URI')\n",
    "NEO4J_USERNAME = os.environ.get('NEO4J_USERNAME')\n",
    "NEO4J_PASSWORD = os.environ.get('NEO4J_PASSWORD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"version\": \"v1\",\n",
    "    \"embedder\": {\n",
    "        \"provider\": \"openai\",\n",
    "        \"config\": {\n",
    "            \"api_key\": OPENAI_API_KEY,\n",
    "            \"model\": \"text-embedding-3-small\"\n",
    "        }\n",
    "    },\n",
    "    \"llm\": {\n",
    "        \"provider\": \"openai\",\n",
    "        \"config\": {\n",
    "            \"api_key\": OPENAI_API_KEY,\n",
    "            \"model\": \"gpt-4.1\"\n",
    "        }\n",
    "    },\n",
    "    \"vector_store\": {\n",
    "        \"provider\": \"qdrant\",\n",
    "        \"config\": {\n",
    "            \"host\": \"localhost\",\n",
    "            \"port\": 6333\n",
    "        }\n",
    "    },\n",
    "    \"graph_store\": {\n",
    "        \"provider\": \"neo4j\",\n",
    "        \"config\": {\n",
    "            \"url\": NEO4J_URL,\n",
    "            \"username\": NEO4J_USERNAME,\n",
    "            \"password\": NEO4J_PASSWORD\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohangore/Documents/projects/python/venv/lib/python3.13/site-packages/pydantic/v1/typing.py:68: DeprecationWarning: Failing to pass a value to the 'type_params' parameter of 'typing.ForwardRef._evaluate' is deprecated, as it leads to incorrect behaviour when calling typing.ForwardRef._evaluate on a stringified annotation that references a PEP 695 type parameter. It will be disallowed in Python 3.15.\n",
      "  return cast(Any, type_)._evaluate(globalns, localns, recursive_guard=set())\n",
      "/Users/rohangore/Documents/projects/python/venv/lib/python3.13/site-packages/pydantic/v1/typing.py:68: DeprecationWarning: Failing to pass a value to the 'type_params' parameter of 'typing.ForwardRef._evaluate' is deprecated, as it leads to incorrect behaviour when calling typing.ForwardRef._evaluate on a stringified annotation that references a PEP 695 type parameter. It will be disallowed in Python 3.15.\n",
      "  return cast(Any, type_)._evaluate(globalns, localns, recursive_guard=set())\n"
     ]
    }
   ],
   "source": [
    "mem_client = Memory.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message):\n",
    "    \"\"\"\n",
    "    1. It will do vector embedding of the message.\n",
    "    2. It will search the vector store for the most similar vectors.\n",
    "    3. It will then find that vector in the graph store to get nodes and relations(edges).\n",
    "    \"\"\"\n",
    "    mem_result = mem_client.search(query = message, user_id=\"user_1\")\n",
    "    \n",
    "    print(\"Memory: \", mem_result)\n",
    "    \n",
    "    # Creating memories from the search results and keep on appeding memory along with score so that it can be used for system context.\n",
    "    memories = \"\"\n",
    "    for memory in mem_result.get('results'):\n",
    "        memories += f\"{str(memory.get('memory'))}:{str(memory.get('score'))}\"\n",
    "        \n",
    "    SYSTEM_PROMPT = f\"\"\"\n",
    "    You are an memory aware fact extraction agent, an advanced AI designed to systematically analyse input content, extract structured knowledge and maintain an optimized memory store. Your primary function is information distillation and knowledge preservation with contextual awareness.\n",
    "    \n",
    "    MEMORY AND SCORING:\n",
    "    memories: {memories}\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\":\"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\":\"user\", \"content\": message},\n",
    "    ]\n",
    "    \n",
    "    openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4.1\",\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    messages.append({\"role\":\"assistant\", \"content\": response.choices[0].message.content})\n",
    "    \n",
    "    # Adding chat history to memory using mem0\n",
    "    mem_client.add(messages, user_id=\"user_1\") # user_id can be uuid.\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory:  {'results': [{'id': '23f43cde-b438-49a2-ad67-7c8023789bf4', 'memory': 'Name is Rohan Gore', 'hash': '86dd4db7ab044fe0e054a0fcfa548b55', 'metadata': None, 'score': 0.22167593, 'created_at': '2025-04-24T17:32:10.471186-07:00', 'updated_at': None, 'user_id': 'user_1'}, {'id': '499be0d9-3624-4f05-a2f2-4773f0065173', 'memory': 'Likes gym', 'hash': 'ec3c988b1086baca60ea7d69b3790ae1', 'metadata': None, 'score': 0.17482793, 'created_at': '2025-04-24T17:30:26.348411-07:00', 'updated_at': None, 'user_id': 'user_1'}, {'id': 'b5c44bc6-4794-41f7-88b6-7c1e6f768e15', 'memory': 'Wants to eat clean food', 'hash': '978ff8c4cb022a71026386dc0737cd28', 'metadata': None, 'score': 0.14967915, 'created_at': '2025-04-24T17:34:04.906914-07:00', 'updated_at': None, 'user_id': 'user_1'}, {'id': '633a6957-30de-4821-a0e2-f341d6ecdc88', 'memory': 'Wants a lean physique', 'hash': '33909a22a0f9f4a112a62a77255fbe7c', 'metadata': None, 'score': 0.1415332, 'created_at': '2025-04-24T17:34:04.890888-07:00', 'updated_at': None, 'user_id': 'user_1'}], 'relations': [{'source': 'user_1', 'relationship': 'likes', 'destination': 'gym'}, {'source': 'user_1', 'relationship': 'name', 'destination': 'rohan_gore'}, {'source': 'user_1', 'relationship': 'wants', 'destination': 'lean_physique'}, {'source': 'user_1', 'relationship': 'wants', 'destination': 'clean_food'}]}\n",
      "BOT:  Hello! How can I assist you today?\n",
      "Memory:  {'results': [{'id': '23f43cde-b438-49a2-ad67-7c8023789bf4', 'memory': 'Name is Rohan Gore', 'hash': '86dd4db7ab044fe0e054a0fcfa548b55', 'metadata': None, 'score': 0.22167593, 'created_at': '2025-04-24T17:32:10.471186-07:00', 'updated_at': None, 'user_id': 'user_1'}, {'id': '499be0d9-3624-4f05-a2f2-4773f0065173', 'memory': 'Likes gym', 'hash': 'ec3c988b1086baca60ea7d69b3790ae1', 'metadata': None, 'score': 0.17482793, 'created_at': '2025-04-24T17:30:26.348411-07:00', 'updated_at': None, 'user_id': 'user_1'}, {'id': 'b5c44bc6-4794-41f7-88b6-7c1e6f768e15', 'memory': 'Wants to eat clean food', 'hash': '978ff8c4cb022a71026386dc0737cd28', 'metadata': None, 'score': 0.14967915, 'created_at': '2025-04-24T17:34:04.906914-07:00', 'updated_at': None, 'user_id': 'user_1'}, {'id': '633a6957-30de-4821-a0e2-f341d6ecdc88', 'memory': 'Wants a lean physique', 'hash': '33909a22a0f9f4a112a62a77255fbe7c', 'metadata': None, 'score': 0.1415332, 'created_at': '2025-04-24T17:34:04.890888-07:00', 'updated_at': None, 'user_id': 'user_1'}], 'relations': [{'source': 'user_1', 'relationship': 'likes', 'destination': 'gym'}, {'source': 'user_1', 'relationship': 'name', 'destination': 'rohan_gore'}, {'source': 'user_1', 'relationship': 'wants', 'destination': 'lean_physique'}, {'source': 'user_1', 'relationship': 'wants', 'destination': 'clean_food'}]}\n",
      "BOT:  Hello! How can I assist you today?\n",
      "Memory:  {'results': [{'id': '23f43cde-b438-49a2-ad67-7c8023789bf4', 'memory': 'Name is Rohan Gore', 'hash': '86dd4db7ab044fe0e054a0fcfa548b55', 'metadata': None, 'score': 0.35477275, 'created_at': '2025-04-24T17:32:10.471186-07:00', 'updated_at': None, 'user_id': 'user_1'}, {'id': '499be0d9-3624-4f05-a2f2-4773f0065173', 'memory': 'Likes gym', 'hash': 'ec3c988b1086baca60ea7d69b3790ae1', 'metadata': None, 'score': 0.10714056, 'created_at': '2025-04-24T17:30:26.348411-07:00', 'updated_at': None, 'user_id': 'user_1'}, {'id': 'b5c44bc6-4794-41f7-88b6-7c1e6f768e15', 'memory': 'Wants to eat clean food', 'hash': '978ff8c4cb022a71026386dc0737cd28', 'metadata': None, 'score': 0.083360404, 'created_at': '2025-04-24T17:34:04.906914-07:00', 'updated_at': None, 'user_id': 'user_1'}, {'id': '633a6957-30de-4821-a0e2-f341d6ecdc88', 'memory': 'Wants a lean physique', 'hash': '33909a22a0f9f4a112a62a77255fbe7c', 'metadata': None, 'score': 0.057238784, 'created_at': '2025-04-24T17:34:04.890888-07:00', 'updated_at': None, 'user_id': 'user_1'}], 'relations': [{'source': 'user_1', 'relationship': 'name', 'destination': 'rohan_gore'}, {'source': 'user_1', 'relationship': 'likes', 'destination': 'gym'}, {'source': 'user_1', 'relationship': 'wants', 'destination': 'lean_physique'}, {'source': 'user_1', 'relationship': 'wants', 'destination': 'clean_food'}]}\n",
      "BOT:  Your name is Rohan Gore.\n",
      "Memory:  {'results': [{'id': '633a6957-30de-4821-a0e2-f341d6ecdc88', 'memory': 'Wants a lean physique', 'hash': '33909a22a0f9f4a112a62a77255fbe7c', 'metadata': None, 'score': 0.35344, 'created_at': '2025-04-24T17:34:04.890888-07:00', 'updated_at': None, 'user_id': 'user_1'}, {'id': 'b5c44bc6-4794-41f7-88b6-7c1e6f768e15', 'memory': 'Wants to eat clean food', 'hash': '978ff8c4cb022a71026386dc0737cd28', 'metadata': None, 'score': 0.34047174, 'created_at': '2025-04-24T17:34:04.906914-07:00', 'updated_at': None, 'user_id': 'user_1'}, {'id': '499be0d9-3624-4f05-a2f2-4773f0065173', 'memory': 'Likes gym', 'hash': 'ec3c988b1086baca60ea7d69b3790ae1', 'metadata': None, 'score': 0.26811102, 'created_at': '2025-04-24T17:30:26.348411-07:00', 'updated_at': None, 'user_id': 'user_1'}, {'id': '23f43cde-b438-49a2-ad67-7c8023789bf4', 'memory': 'Name is Rohan Gore', 'hash': '86dd4db7ab044fe0e054a0fcfa548b55', 'metadata': None, 'score': 0.12600738, 'created_at': '2025-04-24T17:32:10.471186-07:00', 'updated_at': None, 'user_id': 'user_1'}], 'relations': [{'source': 'user_1', 'relationship': 'likes', 'destination': 'gym'}, {'source': 'user_1', 'relationship': 'name', 'destination': 'rohan_gore'}, {'source': 'user_1', 'relationship': 'wants', 'destination': 'lean_physique'}, {'source': 'user_1', 'relationship': 'wants', 'destination': 'clean_food'}]}\n",
      "BOT:  Based on my memory, here is what you like and want:\n",
      "\n",
      "- You want a lean physique.\n",
      "- You want to eat clean food.\n",
      "- You like the gym.\n",
      "\n",
      "Let me know if you’d like to update these preferences or share more about your goals!\n",
      "Memory:  {'results': [{'id': '633a6957-30de-4821-a0e2-f341d6ecdc88', 'memory': 'Wants a lean physique', 'hash': '33909a22a0f9f4a112a62a77255fbe7c', 'metadata': None, 'score': 0.41748908, 'created_at': '2025-04-24T17:34:04.890888-07:00', 'updated_at': None, 'user_id': 'user_1'}, {'id': 'b5c44bc6-4794-41f7-88b6-7c1e6f768e15', 'memory': 'Wants to eat clean food', 'hash': '978ff8c4cb022a71026386dc0737cd28', 'metadata': None, 'score': 0.35916394, 'created_at': '2025-04-24T17:34:04.906914-07:00', 'updated_at': None, 'user_id': 'user_1'}, {'id': '499be0d9-3624-4f05-a2f2-4773f0065173', 'memory': 'Likes gym', 'hash': 'ec3c988b1086baca60ea7d69b3790ae1', 'metadata': None, 'score': 0.2637278, 'created_at': '2025-04-24T17:30:26.348411-07:00', 'updated_at': None, 'user_id': 'user_1'}, {'id': '23f43cde-b438-49a2-ad67-7c8023789bf4', 'memory': 'Name is Rohan Gore', 'hash': '86dd4db7ab044fe0e054a0fcfa548b55', 'metadata': None, 'score': 0.03984516, 'created_at': '2025-04-24T17:32:10.471186-07:00', 'updated_at': None, 'user_id': 'user_1'}], 'relations': []}\n",
      "BOT:  Based on your goals (lean physique, clean food), here are some clean, lean protein options for breakfast:\n",
      "\n",
      "**Animal-based options:**  \n",
      "- Egg whites (very lean, high protein)  \n",
      "- Whole eggs (combine with egg whites for balance)  \n",
      "- Grilled chicken breast (pre-cooked or leftovers)  \n",
      "- Nonfat Greek yogurt or Skyr (high in protein, low in fat/sugar)  \n",
      "- Cottage cheese (low-fat or fat-free)  \n",
      "- Smoked salmon (choose low-sodium if possible)  \n",
      "- Turkey breast slices (low sodium, unprocessed best)\n",
      "\n",
      "**Plant-based options:**  \n",
      "- Tofu scramble (use silken or firm tofu, add veggies)  \n",
      "- Tempeh (lightly sautéed with vegetables)  \n",
      "- Protein oats (add plant protein powder to oatmeal)  \n",
      "- Edamame (boiled, lightly salted)  \n",
      "\n",
      "**Combination meals:**  \n",
      "- Egg white veggie omelet  \n",
      "- Greek yogurt parfait with berries and chia seeds  \n",
      "- Cottage cheese with sliced tomato and pepper  \n",
      "- Whole grain toast with cottage cheese, smoked salmon, and arugula  \n",
      "- Veggie-filled tofu scramble with salsa  \n",
      "\n",
      "**Tips for Clean and Lean Breakfasts:**  \n",
      "- Avoid processed meats (like regular bacon or sausage)  \n",
      "- Choose low-fat, low-sugar dairy  \n",
      "- Incorporate lots of vegetables for volume and nutrition  \n",
      "- Watch added sugars and processed carbs  \n",
      "\n",
      "Let me know if you prefer vegetarian or non-vegetarian, and I can give you a more tailored meal suggestion!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m      2\u001b[39m     message = \u001b[38;5;28minput\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m>>\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBOT: \u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mchat\u001b[39m\u001b[34m(message)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchat\u001b[39m(message):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    1. It will do vector embedding of the message.\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    2. It will search the vector store for the most similar vectors.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m    3. It will then find that vector in the graph store to get nodes and relations(edges).\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     mem_result = \u001b[43mmem_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser_1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMemory: \u001b[39m\u001b[33m\"\u001b[39m, mem_result)\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# Creating memories from the search results and keep on appeding memory along with score so that it can be used for system context.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/python/venv/lib/python3.13/site-packages/mem0/memory/main.py:508\u001b[39m, in \u001b[36mMemory.search\u001b[39m\u001b[34m(self, query, user_id, agent_id, run_id, limit, filters)\u001b[39m\n\u001b[32m    503\u001b[39m future_memories = executor.submit(\u001b[38;5;28mself\u001b[39m._search_vector_store, query, filters, limit)\n\u001b[32m    504\u001b[39m future_graph_entities = (\n\u001b[32m    505\u001b[39m     executor.submit(\u001b[38;5;28mself\u001b[39m.graph.search, query, filters, limit) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.enable_graph \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    506\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m508\u001b[39m \u001b[43mconcurrent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mfuture_memories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture_graph_entities\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfuture_graph_entities\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mfuture_memories\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    512\u001b[39m original_memories = future_memories.result()\n\u001b[32m    513\u001b[39m graph_entities = future_graph_entities.result() \u001b[38;5;28;01mif\u001b[39;00m future_graph_entities \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py:305\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(fs, timeout, return_when)\u001b[39m\n\u001b[32m    301\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m DoneAndNotDoneFutures(done, not_done)\n\u001b[32m    303\u001b[39m     waiter = _create_and_install_waiters(fs, return_when)\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fs:\n\u001b[32m    307\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m f._condition:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py:659\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    657\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m659\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    message = input(\">>\")\n",
    "    print(\"BOT: \", chat(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
